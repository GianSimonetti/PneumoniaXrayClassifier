{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMX/0D/PyFcc/9IEiWSWbDc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Entrenamiento de modelo para clasificar radiografias de pacientes con o sin neumonía</h1>\n",
        "Este proyecto tiene como objetivo entrenar un modelo de modo que pueda distinguir entre radiografías de pacientes sanos y radiografías de pacientes con neumonía. El modelo de IA se entrena y evalúa utilizando el entorno de Google Colab y datos almacenados en Google Drive. Previo al entrenamiento del modelo, se descomprimen las carpetas con imagenes (se brinda el codigo por si resulta util). Toda la información se trabaja desde Google Drive para facilitar el acceso, también se proporciona el codigo para montar las carpetas correspondientes ubicadas en Google Drive.\n",
        "\n",
        "<h2>Pasos</h2>\n",
        "\n",
        "**Carga de Datos:**\n",
        "\n",
        "Las imágenes de radiografías se clasifican en dos categorías: NORMAL y PNEUMONIA. Previamente, las imagenes comprimidas se descomprimen y ubican en carpetas denominadas 'Train' y 'Test' respectivamente, con el codigo proporcionado.\n",
        "Las imágenes se cargan desde dichos directorios específicos, segun esten ubicadas en NORMAL o PNEUMONIA se les asignan etiquetas y se preprocesan, ajustándose a un tamaño uniforme y convirtiéndose a escala de grises.\n",
        "Los datos procesados se guardan en archivos para evitar recargas constantes, esto lo hice en una carpeta nueva denominada imagenesAlmacenadas a modo de evitar realizar la carga constantemente y evitar demoras innecesarias.\n",
        "\n",
        "**Estructura del Modelo:**\n",
        "\n",
        "Se utiliza un modelo de red neuronal convolucional (CNN) con varias capas convolucionales y de pooling.\n",
        "El modelo se compila con el optimizador adam y la función de pérdida sparse_categorical_crossentropy.\n",
        "\n",
        "**Entrenamiento y Evaluación:**\n",
        "\n",
        "El modelo se entrena con las imágenes preprocesadas durante 20 épocas.\n",
        "Se utiliza TensorBoard para el seguimiento del entrenamiento.\n",
        "La precisión del modelo se evalúa tanto en los datos de entrenamiento como en los datos de prueba.\n"
      ],
      "metadata": {
        "id": "FZPm-jSSxyTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importacion de librerias"
      ],
      "metadata": {
        "id": "-TMRqvp1q48V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnVw38ZvkcPM"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm #barra de progreso\n",
        "import cv2\n",
        "from glob import glob\n",
        "\n",
        "#para redimencionar\n",
        "import sklearn\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Montar en el arbol de carpetas contenido en drive (opcional)"
      ],
      "metadata": {
        "id": "5cmH7l_9q-ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3xWEQet6qTeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listar el contenido de la carpeta principal de mi Drive\n",
        "!ls /content/drive/My\\ Drive/"
      ],
      "metadata": {
        "id": "a1csaNm8ei57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/"
      ],
      "metadata": {
        "id": "NXHaJJBnejT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Codigo para descomprimir archivos"
      ],
      "metadata": {
        "id": "-NJ0IoZtrU94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def descomprimir_zip(ruta_zip, directorio_destino):\n",
        "    # Verificar si el directorio de destino existe, si no, crearlo\n",
        "    if not os.path.exists(directorio_destino):\n",
        "        os.makedirs(directorio_destino)\n",
        "\n",
        "    # Verificar el formato del archivo ZIP\n",
        "    with open(ruta_zip, 'rb') as archivo:\n",
        "        firma = archivo.read(4)\n",
        "        if firma != b'PK\\x03\\x04':\n",
        "            raise zipfile.BadZipFile(\"File is not a zip file\")\n",
        "\n",
        "    # Abrir el archivo ZIP\n",
        "    with zipfile.ZipFile(ruta_zip, 'r') as archivo_zip:\n",
        "        # Extraer todo el contenido en el directorio de destino\n",
        "        archivo_zip.extractall(directorio_destino)\n",
        "\n",
        "# Ejemplo de uso\n",
        "ruta_zip = 'carpeta comprimida con imagenes'\n",
        "directorio_destino = 'destino elegido para descomprimir la carpeta con imagenes'\n",
        "\n",
        "if os.path.exists(ruta_zip):\n",
        "    try:\n",
        "        descomprimir_zip(ruta_zip, directorio_destino)\n",
        "    except zipfile.BadZipFile as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"El archivo no existe en la ruta especificada\")"
      ],
      "metadata": {
        "id": "RjlaUlNderhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Carga de Datos"
      ],
      "metadata": {
        "id": "AZ4SwsyqrzrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"Ruta de carpeta descomprimida con imagenes de entrenamiento\"\n",
        "test_dir =  \"Ruta de carpeta descomprimida con imagenes de test\"\n",
        "\n",
        "#Cuando el FLAG se utiliza en false, no se recargan los datos nuevamnete, para evitar demoras innecesarias.\n",
        "LOAD_FROM_IMAGES = False\n",
        "\n",
        "#Clasificamos las imagenes añadiendo una etiqueta segun sea imagen normal o con neumonia\n",
        "def get_data(folder):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for folderName in os.listdir(folder):\n",
        "        if not folderName.startswith('.'):\n",
        "            if folderName in ['NORMAL']:\n",
        "                label = 0 #Etiquetas segun donde se ubiquen las imagenes\n",
        "            elif folderName in ['PNEUMONIA']:\n",
        "                label = 1 #Etiquetas segun donde se ubiquen las imagenes\n",
        "            else:\n",
        "                label = 2 #Etiquetas segun donde se ubiquen las imagenes\n",
        "            for image_filename in tqdm(os.listdir(folder + folderName)):\n",
        "                img_file = cv2.imread(folder + folderName + '/' + image_filename)\n",
        "                if img_file is not None:\n",
        "                    img_file = skimage.transform.resize(img_file, (150, 150, 3),mode='constant',anti_aliasing=True)\n",
        "                    img_file = rgb2gray(img_file)\n",
        "                    img_arr = np.asarray(img_file)\n",
        "                    X.append(img_arr)\n",
        "                    Y.append(label)\n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)\n",
        "    return X,Y\n",
        "\n",
        "#Una vez guardadas las imagenes en los arrays, usamos los arrays con la informacion de test y train, para no cargar constantemente las imagenes\n",
        "if LOAD_FROM_IMAGES:\n",
        "    #cargamos las imágenes a los arrays\n",
        "    X_train, y_train = get_data(train_dir)\n",
        "    X_test, y_test= get_data(test_dir)\n",
        "\n",
        "    #grabamos los arrays en archivos\n",
        "    np.save('Ruta para almacenar imagenes de entrenamiento', X_train) #Cree una carpeta nueva en Google Drive para almacenar toda esta informacion\n",
        "    np.save('Ruta para almacenar etiquetas de entrenamiento', y_train) #Cree una carpeta nueva en Google Drive para almacenar toda esta informacion\n",
        "    np.save('Ruta para almacenar imagenes de test', X_test) #Cree una carpeta nueva en Google Drive para almacenar toda esta informacion\n",
        "    np.save('Ruta para almacenar etiquetas de test', y_test) #Cree una carpeta nueva en Google Drive para almacenar toda esta informacion\n",
        "else:\n",
        "    #cargamos los arrays anteriormente grabados para evitar recargas constantes\n",
        "    X_train = np.load('Ruta para cargar imagenes de entrenamiento')\n",
        "    y_train = np.load('Ruta para cargar etiquetas de entrenamiento')\n",
        "    X_test = np.load('Ruta para cargar imagenes de test')\n",
        "    y_test = np.load('Ruta para cargar etiquetas de test')\n",
        "\n"
      ],
      "metadata": {
        "id": "fsVhhRSHffsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Muestreo"
      ],
      "metadata": {
        "id": "7EKzBxktsUXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#impresion de una imagen al azar para visualizar\n",
        "def plotHistogram(a):\n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(a.ravel(), bins=255)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(a, cmap='gray', vmin=0, vmax=1)\n",
        "    plt.show()\n",
        "\n",
        "plotHistogram(X_train[3])"
      ],
      "metadata": {
        "id": "zUsQ9kxHpEqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"No Neumonía\")\n",
        "#Encontrar archivos en carpetas y subcarpetas\n",
        "multipleImages = glob('Ruta de imagenes descomprimidas para entrenamiento sin Neumonia')\n",
        "i_ = 0\n",
        "plt.rcParams['figure.figsize'] = (20.0, 20.0)\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "for l in multipleImages[:25]:\n",
        "    im = cv2.imread(l)\n",
        "    im = cv2.resize(im, (128, 128))\n",
        "    plt.subplot(5, 5, i_+1)\n",
        "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n",
        "    i_ += 1"
      ],
      "metadata": {
        "id": "TlFZChVwHCeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Si neumonía\")\n",
        "#Encontrar archivos en carpetas y subcarpetas\n",
        "multipleImages = glob('Ruta de imagenes descomprimidas para entrenamiento con Neumonia')\n",
        "i_ = 0\n",
        "plt.rcParams['figure.figsize'] = (20.0, 20.0)\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "for l in multipleImages[:25]:\n",
        "    im = cv2.imread(l)\n",
        "    im = cv2.resize(im, (128, 128))\n",
        "    plt.subplot(5, 5, i_+1)\n",
        "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n",
        "    i_ += 1"
      ],
      "metadata": {
        "id": "dtWc_F9vHOOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Comprobacion de balanceo en cantidad de imagenes\n",
        "plt.figure(figsize=(8,4))\n",
        "map_characters = {0: 'No Neumonía', 1: 'Si Neumonía'}\n",
        "dict_characters=map_characters\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df[\"labels\"]=y_train\n",
        "lab = df['labels']\n",
        "dist = lab.value_counts()\n",
        "sns.countplot(lab)\n",
        "print(dict_characters)"
      ],
      "metadata": {
        "id": "JEMPTn8cIjQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Estructura y Configuracion del modelo"
      ],
      "metadata": {
        "id": "W52ZlBqAshMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Redimension de imagenes acorde a la configuracion del modelo elegido\n",
        "X_trainReshaped = X_train.reshape(len(X_train),150,150,1)\n",
        "X_testReshaped = X_test.reshape(len(X_test),150,150,1)"
      ],
      "metadata": {
        "id": "e6KktrEfJInw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential() #Creación de modelo secuencial\n",
        "\n",
        "#Capas de convolución\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "\n",
        "model.add(layers.Flatten()) #Conversion de características 2D en un vector de una dimensión\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary() #Muestreo"
      ],
      "metadata": {
        "id": "otdAhwNRNvvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Entrenamiento y Evaluación"
      ],
      "metadata": {
        "id": "bBAHfTbgsm9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "log_dir=\"Ruta para almacenar los registros de TensorBoard\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir, histogram_freq=1)\n",
        "\n",
        "model.fit(X_trainReshaped,\n",
        "          y_train,\n",
        "          epochs=20,\n",
        "          validation_data = (X_testReshaped,y_test),\n",
        "          callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "zT-rhvQ9N0Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_testReshaped, y_test)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "Uu4Vo_5SN5Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_trainReshaped, y_train)"
      ],
      "metadata": {
        "id": "JK6Da_-5N7Aq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}